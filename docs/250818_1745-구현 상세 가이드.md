# FastAPI AI 서비스 구현 상세 가이드

**작성일**: 2025-08-18 17:45  
**연관 문서**: [250818_1745-아키텍처 개선 방향 및 구현 계획.md]  
**목적**: AI 서비스 통합을 위한 구체적 구현 방법 제시

---

## 🏗️ 구현 단계별 상세 가이드

### Step 1: 환경 설정 및 의존성 추가

#### 1.1 Poetry 의존성 추가
```bash
cd backend
poetry add langchain==0.1.20
poetry add langchain-openai==0.1.8
poetry add langgraph==0.1.5
poetry add openai==1.35.0
poetry add tiktoken==0.7.0
poetry add pydantic-ai==0.0.12
```

#### 1.2 환경 변수 설정
```bash
# backend/.env
# 기존 변수 유지
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_key
JWT_SECRET_KEY=your_jwt_secret

# 새로 추가
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o-mini
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langchain_api_key  # 선택사항
```

#### 1.3 설정 파일 업데이트
```python
# backend/app/core/config.py
class Settings(BaseSettings):
    # 기존 설정 유지
    app_name: str = "Memento Box API"
    # ... 기존 설정들 ...
    
    # AI 서비스 설정 추가
    openai_api_key: str
    openai_model: str = "gpt-4o-mini"
    max_tokens: int = 1000
    temperature: float = 0.7
    
    # LangChain 설정 (선택사항)
    langchain_tracing_v2: bool = False
    langchain_api_key: Optional[str] = None
```

---

### Step 2: AI 서비스 기본 구조 구현

#### 2.1 디렉토리 구조 생성
```bash
mkdir -p backend/app/services
mkdir -p backend/app/agents
mkdir -p backend/app/prompts
touch backend/app/services/__init__.py
touch backend/app/agents/__init__.py
touch backend/app/prompts/__init__.py
```

#### 2.2 기본 AI 서비스 클래스
```python
# backend/app/services/ai_service.py
from langchain_openai import ChatOpenAI
from langchain.schema import BaseMessage, HumanMessage, SystemMessage
from typing import List, Dict, Any, Optional
import logging
from ..core.config import settings

logger = logging.getLogger(__name__)

class AIService:
    """기본 AI 서비스 클래스"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.openai_model,
            temperature=settings.temperature,
            max_tokens=settings.max_tokens,
            api_key=settings.openai_api_key
        )
        
    async def generate_response(
        self, 
        messages: List[BaseMessage],
        **kwargs
    ) -> str:
        """AI 응답 생성"""
        try:
            response = await self.llm.ainvoke(messages, **kwargs)
            return response.content
        except Exception as e:
            logger.error(f"AI response generation failed: {e}")
            raise
    
    async def analyze_photo(
        self, 
        photo_url: str, 
        user_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """사진 분석 및 대화 소재 생성"""
        system_prompt = """
        당신은 사진을 분석하여 회상 대화를 도와주는 AI입니다.
        사진의 내용을 분석하고 다음 정보를 제공해주세요:
        1. 사진 설명
        2. 대화 시작 질문 3개
        3. 감정적 톤 (긍정적/중립적/조심스러운)
        4. 예상 기억 카테고리 (가족, 여행, 일상, 특별한 순간 등)
        """
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"사진 URL: {photo_url}\n사용자 정보: {user_context}")
        ]
        
        response = await self.generate_response(messages)
        
        # TODO: 구조화된 응답 파싱 로직 구현
        return {
            "description": "사진 분석 결과",
            "conversation_starters": [],
            "emotional_tone": "positive",
            "memory_category": "general"
        }

# 싱글톤 인스턴스
ai_service = AIService()
```

#### 2.3 CIST 평가 서비스
```python
# backend/app/services/cist_service.py
from typing import Dict, List, Optional
from enum import Enum
import re
from ..models.session import CISTCategory
from .ai_service import ai_service
from langchain.schema import SystemMessage, HumanMessage

class CISTDifficulty(Enum):
    EASY = 1
    MEDIUM = 2
    HARD = 3

class CISTService:
    """CIST 인지평가 서비스"""
    
    def __init__(self):
        self.ai_service = ai_service
        self.category_prompts = {
            "orientation_time": "시간 지남력 관련 질문을 생성해주세요.",
            "orientation_place": "장소 지남력 관련 질문을 생성해주세요.",
            "memory_registration": "기억 등록 능력 평가 질문을 생성해주세요.",
            "memory_recall": "기억 회상 능력 평가 질문을 생성해주세요.",
            "attention": "주의집중력 평가 질문을 생성해주세요.",
            "executive_function": "실행기능 평가 질문을 생성해주세요.",
            "language_naming": "언어명명 능력 평가 질문을 생성해주세요."
        }
    
    async def generate_question(
        self, 
        category: str,
        difficulty: int = 1,
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """CIST 카테고리별 질문 생성"""
        
        system_prompt = f"""
        당신은 CIST(한국판 간이인지검사) 전문가입니다.
        {category} 카테고리의 난이도 {difficulty} 질문을 생성해주세요.
        
        응답 형식:
        {{
            "question": "질문 내용",
            "expected_answer": "예상 정답",
            "scoring_criteria": "채점 기준",
            "max_score": 점수
        }}
        """
        
        category_instruction = self.category_prompts.get(
            category, 
            "인지능력 평가 질문을 생성해주세요."
        )
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=category_instruction)
        ]
        
        response = await self.ai_service.generate_response(messages)
        
        # TODO: JSON 파싱 및 검증 로직 구현
        return {
            "question": "오늘은 몇 월 며칠입니까?",
            "expected_answer": "정확한 월/일",
            "scoring_criteria": "정확하면 1점, 틀리면 0점",
            "max_score": 1
        }
    
    async def evaluate_response(
        self,
        question: str,
        expected_answer: str,
        user_response: str,
        category: str
    ) -> Dict[str, Any]:
        """사용자 응답 평가 및 점수 계산"""
        
        system_prompt = f"""
        CIST {category} 카테고리 응답을 평가해주세요.
        
        질문: {question}
        예상 정답: {expected_answer}
        사용자 응답: {user_response}
        
        평가 기준:
        1. 정확도 (0-1점)
        2. 부분 점수 가능성
        3. 평가 근거
        
        응답 형식:
        {{
            "score": 점수,
            "is_correct": true/false,
            "partial_credit": 부분점수,
            "feedback": "평가 근거"
        }}
        """
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content="위 응답을 평가해주세요.")
        ]
        
        response = await self.ai_service.generate_response(messages)
        
        # TODO: 구조화된 평가 결과 파싱
        return {
            "score": 1,
            "is_correct": True,
            "partial_credit": 0.0,
            "feedback": "정확한 응답입니다."
        }
    
    async def calculate_total_score(self, session_id: str) -> Dict[str, Any]:
        """세션별 CIST 총점 및 카테고리별 점수 계산"""
        # TODO: 데이터베이스에서 세션 응답 조회 및 집계
        return {
            "total_score": 18,
            "max_possible": 21,
            "category_scores": {
                "orientation": 4,
                "memory": 6,
                "attention": 3,
                "executive": 3,
                "language": 2
            },
            "cognitive_status": "normal"
        }

# 싱글톤 인스턴스
cist_service = CISTService()
```

#### 2.4 회상 대화 서비스 (LangGraph 활용)
```python
# backend/app/services/conversation_service.py
from langgraph import StateGraph, END
from typing import Dict, List, Any, TypedDict
import uuid
from .ai_service import ai_service
from ..core.database import supabase

class ConversationState(TypedDict):
    """대화 상태 정의"""
    session_id: str
    user_id: str
    current_photo_id: str
    conversation_history: List[Dict[str, str]]
    current_question: str
    user_response: str
    conversation_stage: str  # "intro", "exploring", "deepening", "closing"
    emotional_tone: str
    next_action: str

class ConversationService:
    """LangGraph 기반 회상 대화 서비스"""
    
    def __init__(self):
        self.ai_service = ai_service
        self.conversation_graph = self._build_conversation_graph()
    
    def _build_conversation_graph(self) -> StateGraph:
        """대화 흐름 그래프 생성"""
        workflow = StateGraph(ConversationState)
        
        # 노드 추가
        workflow.add_node("start_conversation", self._start_conversation)
        workflow.add_node("generate_question", self._generate_question)
        workflow.add_node("process_response", self._process_response)
        workflow.add_node("determine_next", self._determine_next_step)
        workflow.add_node("end_conversation", self._end_conversation)
        
        # 엣지 추가
        workflow.set_entry_point("start_conversation")
        workflow.add_edge("start_conversation", "generate_question")
        workflow.add_edge("generate_question", "process_response")
        workflow.add_edge("process_response", "determine_next")
        
        # 조건부 엣지
        workflow.add_conditional_edges(
            "determine_next",
            self._should_continue,
            {
                "continue": "generate_question",
                "end": "end_conversation"
            }
        )
        
        workflow.add_edge("end_conversation", END)
        
        return workflow.compile()
    
    async def _start_conversation(self, state: ConversationState) -> ConversationState:
        """대화 시작"""
        state["conversation_stage"] = "intro"
        state["emotional_tone"] = "warm"
        
        # 첫 번째 사진 정보 조회
        photo_result = supabase.table("photos").select("*").eq("id", state["current_photo_id"]).execute()
        if photo_result.data:
            photo = photo_result.data[0]
            # 사진 분석을 통한 초기 질문 생성
            analysis = await self.ai_service.analyze_photo(
                photo["file_path"], 
                {"user_id": state["user_id"]}
            )
            state["current_question"] = analysis.get("conversation_starters", ["이 사진에 대해 말씀해 주세요."])[0]
        
        return state
    
    async def _generate_question(self, state: ConversationState) -> ConversationState:
        """다음 질문 생성"""
        system_prompt = f"""
        당신은 전문적인 회상 대화 치료사입니다.
        현재 대화 단계: {state['conversation_stage']}
        감정적 톤: {state['emotional_tone']}
        
        이전 대화 내용을 바탕으로 적절한 후속 질문을 생성해주세요.
        질문은 자연스럽고 공감적이어야 하며, 기억을 자극하는 내용이어야 합니다.
        """
        
        # 대화 히스토리 구성
        history_text = "\n".join([
            f"질문: {conv['question']}\n응답: {conv['response']}"
            for conv in state["conversation_history"]
        ])
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"대화 내역:\n{history_text}\n\n다음 질문을 생성해주세요."}
        ]
        
        next_question = await self.ai_service.generate_response(messages)
        state["current_question"] = next_question
        
        return state
    
    async def _process_response(self, state: ConversationState) -> ConversationState:
        """사용자 응답 처리"""
        # 응답을 대화 히스토리에 추가
        state["conversation_history"].append({
            "question": state["current_question"],
            "response": state["user_response"],
            "timestamp": "2025-08-18T17:45:00Z"  # 실제로는 현재 시간
        })
        
        # 감정 톤 분석 및 조정
        # TODO: 사용자 응답의 감정 상태 분석
        
        return state
    
    async def _determine_next_step(self, state: ConversationState) -> ConversationState:
        """다음 단계 결정"""
        # 대화 길이, 사용자 참여도 등을 고려하여 다음 행동 결정
        conversation_length = len(state["conversation_history"])
        
        if conversation_length < 3:
            state["next_action"] = "continue"
            state["conversation_stage"] = "exploring"
        elif conversation_length < 6:
            state["next_action"] = "continue"
            state["conversation_stage"] = "deepening"
        else:
            state["next_action"] = "end"
            state["conversation_stage"] = "closing"
        
        return state
    
    def _should_continue(self, state: ConversationState) -> str:
        """대화 계속 여부 판단"""
        return state["next_action"]
    
    async def _end_conversation(self, state: ConversationState) -> ConversationState:
        """대화 종료"""
        # 대화 세션 데이터베이스 저장
        session_data = {
            "id": state["session_id"],
            "status": "completed",
            "total_duration_seconds": len(state["conversation_history"]) * 120,  # 추정치
        }
        
        # TODO: 실제 데이터베이스 업데이트 구현
        
        return state
    
    async def start_conversation(
        self,
        user_id: str,
        photo_ids: List[str]
    ) -> str:
        """새 회상 대화 세션 시작"""
        session_id = str(uuid.uuid4())
        
        initial_state: ConversationState = {
            "session_id": session_id,
            "user_id": user_id,
            "current_photo_id": photo_ids[0] if photo_ids else "",
            "conversation_history": [],
            "current_question": "",
            "user_response": "",
            "conversation_stage": "intro",
            "emotional_tone": "warm",
            "next_action": "continue"
        }
        
        # 데이터베이스에 세션 생성
        session_data = {
            "user_id": user_id,
            "session_type": "reminiscence",
            "status": "active",
            "selected_photos": photo_ids
        }
        
        result = supabase.table("sessions").insert(session_data).execute()
        
        return session_id
    
    async def process_user_input(
        self,
        session_id: str,
        user_input: str
    ) -> Dict[str, Any]:
        """사용자 입력 처리 및 다음 질문 생성"""
        
        # 현재 상태 복원 (실제로는 캐시/DB에서 조회)
        current_state: ConversationState = {
            "session_id": session_id,
            "user_id": "temp_user",  # 실제로는 세션에서 조회
            "current_photo_id": "temp_photo",
            "conversation_history": [],
            "current_question": "",
            "user_response": user_input,
            "conversation_stage": "exploring",
            "emotional_tone": "warm",
            "next_action": "continue"
        }
        
        # 대화 그래프 실행
        result = await self.conversation_graph.ainvoke(current_state)
        
        return {
            "next_question": result["current_question"],
            "conversation_stage": result["conversation_stage"],
            "should_continue": result["next_action"] == "continue"
        }

# 싱글톤 인스턴스
conversation_service = ConversationService()
```

---

### Step 3: API 라우터 구현

#### 3.1 AI 라우터 생성
```python
# backend/app/routers/ai_router.py
from fastapi import APIRouter, HTTPException, Depends, status
from typing import List, Dict, Any, Optional
from ..services.conversation_service import conversation_service
from ..services.cist_service import cist_service
from ..core.deps import get_current_user_id
from ..models.ai import (  # 새로 생성 필요
    ConversationStartRequest,
    ConversationResponse,
    CISTQuestionRequest,
    CISTEvaluationRequest,
    AIResponse
)

router = APIRouter(prefix="/ai", tags=["ai"])

# 회상 대화 엔드포인트
@router.post("/conversations/start", response_model=AIResponse)
async def start_conversation(
    request: ConversationStartRequest,
    current_user_id: str = Depends(get_current_user_id)
):
    """회상 대화 세션 시작"""
    try:
        session_id = await conversation_service.start_conversation(
            user_id=current_user_id,
            photo_ids=request.photo_ids
        )
        
        return AIResponse(
            success=True,
            message="대화 세션이 시작되었습니다.",
            data={"session_id": session_id}
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"대화 시작 실패: {str(e)}"
        )

@router.post("/conversations/{session_id}/respond", response_model=ConversationResponse)
async def process_conversation_response(
    session_id: str,
    user_input: str,
    current_user_id: str = Depends(get_current_user_id)
):
    """사용자 응답 처리 및 다음 질문 생성"""
    try:
        result = await conversation_service.process_user_input(
            session_id=session_id,
            user_input=user_input
        )
        
        return ConversationResponse(
            session_id=session_id,
            next_question=result["next_question"],
            conversation_stage=result["conversation_stage"],
            should_continue=result["should_continue"]
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"응답 처리 실패: {str(e)}"
        )

# CIST 평가 엔드포인트
@router.post("/cist/question")
async def generate_cist_question(
    request: CISTQuestionRequest,
    current_user_id: str = Depends(get_current_user_id)
):
    """CIST 질문 생성"""
    try:
        question = await cist_service.generate_question(
            category=request.category,
            difficulty=request.difficulty
        )
        
        return AIResponse(
            success=True,
            message="CIST 질문이 생성되었습니다.",
            data=question
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"질문 생성 실패: {str(e)}"
        )

@router.post("/cist/evaluate")
async def evaluate_cist_response(
    request: CISTEvaluationRequest,
    current_user_id: str = Depends(get_current_user_id)
):
    """CIST 응답 평가"""
    try:
        evaluation = await cist_service.evaluate_response(
            question=request.question,
            expected_answer=request.expected_answer,
            user_response=request.user_response,
            category=request.category
        )
        
        return AIResponse(
            success=True,
            message="응답이 평가되었습니다.",
            data=evaluation
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"응답 평가 실패: {str(e)}"
        )
```

#### 3.2 AI 모델 정의
```python
# backend/app/models/ai.py
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

class ConversationStartRequest(BaseModel):
    photo_ids: List[str]
    session_type: Optional[str] = "reminiscence"

class ConversationResponse(BaseModel):
    session_id: str
    next_question: str
    conversation_stage: str
    should_continue: bool

class CISTQuestionRequest(BaseModel):
    category: str
    difficulty: int = 1
    context: Optional[Dict[str, Any]] = None

class CISTEvaluationRequest(BaseModel):
    question: str
    expected_answer: str
    user_response: str
    category: str

class AIResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
```

#### 3.3 메인 앱에 라우터 추가
```python
# backend/app/main.py
from .routers import auth_router, users_router, photos_router, sessions_router, ai_router  # 추가

# 라우터 등록
app.include_router(ai_router, prefix=API_V1_PREFIX)  # 추가
```

---

### Step 4: 테스트 및 검증

#### 4.1 기본 테스트 스크립트
```python
# backend/test_ai_services.py
import asyncio
import os
from dotenv import load_dotenv

load_dotenv()

async def test_ai_service():
    """AI 서비스 기본 테스트"""
    from app.services.ai_service import ai_service
    from langchain.schema import HumanMessage
    
    # 기본 응답 테스트
    messages = [HumanMessage(content="안녕하세요, 테스트입니다.")]
    response = await ai_service.generate_response(messages)
    print(f"AI 응답: {response}")

async def test_cist_service():
    """CIST 서비스 테스트"""
    from app.services.cist_service import cist_service
    
    # 질문 생성 테스트
    question = await cist_service.generate_question("orientation_time", 1)
    print(f"생성된 질문: {question}")
    
    # 응답 평가 테스트
    evaluation = await cist_service.evaluate_response(
        "오늘은 몇 월 며칠입니까?",
        "8월 18일",
        "8월 18일이요",
        "orientation_time"
    )
    print(f"평가 결과: {evaluation}")

if __name__ == "__main__":
    asyncio.run(test_ai_service())
    asyncio.run(test_cist_service())
```

#### 4.2 API 엔드포인트 테스트
```bash
# 회상 대화 시작 테스트
curl -X POST "http://localhost:8000/api/v1/ai/conversations/start" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "photo_ids": ["photo-id-1", "photo-id-2"]
  }'

# CIST 질문 생성 테스트
curl -X POST "http://localhost:8000/api/v1/ai/cist/question" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "category": "orientation_time",
    "difficulty": 1
  }'
```

---

### Step 5: 프론트엔드 통합 준비

#### 5.1 API 클라이언트 수정
```typescript
// frontend/src/lib/api.ts
class APIClient {
  private baseURL = 'http://localhost:8000/api/v1';
  private token: string | null = null;

  setAuthToken(token: string) {
    this.token = token;
  }

  private async request(endpoint: string, options: RequestInit = {}) {
    const url = `${this.baseURL}${endpoint}`;
    const headers = {
      'Content-Type': 'application/json',
      ...(this.token && { Authorization: `Bearer ${this.token}` }),
      ...options.headers,
    };

    const response = await fetch(url, { ...options, headers });
    return response.json();
  }

  // AI 서비스 관련 메서드들
  async startConversation(photoIds: string[]) {
    return this.request('/ai/conversations/start', {
      method: 'POST',
      body: JSON.stringify({ photo_ids: photoIds }),
    });
  }

  async respondToConversation(sessionId: string, userInput: string) {
    return this.request(`/ai/conversations/${sessionId}/respond`, {
      method: 'POST',
      body: JSON.stringify({ user_input: userInput }),
    });
  }

  async generateCISTQuestion(category: string, difficulty: number = 1) {
    return this.request('/ai/cist/question', {
      method: 'POST',
      body: JSON.stringify({ category, difficulty }),
    });
  }
}

export const apiClient = new APIClient();
```

#### 5.2 React 훅 생성
```typescript
// frontend/src/hooks/useConversation.ts
import { useState, useCallback } from 'react';
import { apiClient } from '../lib/api';

export interface ConversationState {
  sessionId: string | null;
  currentQuestion: string;
  conversationHistory: Array<{
    question: string;
    response: string;
  }>;
  isActive: boolean;
  stage: string;
}

export function useConversation() {
  const [conversation, setConversation] = useState<ConversationState>({
    sessionId: null,
    currentQuestion: '',
    conversationHistory: [],
    isActive: false,
    stage: 'idle',
  });

  const startConversation = useCallback(async (photoIds: string[]) => {
    try {
      const response = await apiClient.startConversation(photoIds);
      
      if (response.success) {
        setConversation(prev => ({
          ...prev,
          sessionId: response.data.session_id,
          isActive: true,
          stage: 'intro',
        }));
      }
    } catch (error) {
      console.error('대화 시작 실패:', error);
    }
  }, []);

  const respondToConversation = useCallback(async (userInput: string) => {
    if (!conversation.sessionId) return;

    try {
      const response = await apiClient.respondToConversation(
        conversation.sessionId,
        userInput
      );

      setConversation(prev => ({
        ...prev,
        currentQuestion: response.next_question,
        conversationHistory: [
          ...prev.conversationHistory,
          { question: prev.currentQuestion, response: userInput }
        ],
        stage: response.conversation_stage,
        isActive: response.should_continue,
      }));
    } catch (error) {
      console.error('응답 처리 실패:', error);
    }
  }, [conversation.sessionId]);

  return {
    conversation,
    startConversation,
    respondToConversation,
  };
}
```

---

## 🚀 실행 순서

### 1. 환경 설정
```bash
# 의존성 설치
cd backend
poetry install

# 환경 변수 설정
cp .env.example .env
# .env 파일에 OpenAI API 키 추가
```

### 2. 서비스 테스트
```bash
# AI 서비스 테스트
poetry run python test_ai_services.py
```

### 3. API 서버 시작
```bash
# 개발 서버 실행
poetry run python run_server.py
```

### 4. API 문서 확인
브라우저에서 `http://localhost:8000/docs` 접속하여 새로운 AI 엔드포인트 확인

---

## 🔧 트러블슈팅

### 일반적인 문제들
1. **OpenAI API 키 오류**: 환경 변수 설정 확인
2. **의존성 충돌**: `poetry lock --no-update` 실행
3. **메모리 부족**: LangChain 모델 캐싱 설정 조정
4. **응답 지연**: OpenAI API 타임아웃 설정 증가

### 로깅 설정
```python
# backend/app/core/config.py에 추가
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# AI 서비스 전용 로거
logger = logging.getLogger('memento.ai')
```

---

*이 가이드를 따라 구현하면 기본적인 AI 서비스가 FastAPI에 통합됩니다. 각 단계별로 테스트하며 점진적으로 구현해 나가세요.*