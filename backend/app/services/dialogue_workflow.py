from typing import TypedDict, List, Dict, Any, Optional
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import os
from supabase import create_client, Client
import uuid
from datetime import datetime
from app.core.config import settings
from .dialogue_prompt import (
    ROUTER_PROMPT,
    STANDARD_RESPONSE_PROMPT,
    FALLBACK_PROMPT,
    CACHE_RETRIEVE_AND_EVALUATE_PROMPT
)

class WorkflowInput(TypedDict):
    """ê·¸ë˜í”„ ì‹¤í–‰ì„ ìœ„í•´ ì™¸ë¶€ì—ì„œ ì£¼ì…ë˜ëŠ” ì´ˆê¸° ë°ì´í„°"""
    conversation_id: str
    user_id: str
    user_message: str
    photo_context: Dict[str, Any]

class IntermediateState(TypedDict):
    """ë…¸ë“œ ê°„ ê²°ì •ì— ì‚¬ìš©ë˜ëŠ” ì„ì‹œ ë°ì´í„°"""
    cache_score: Optional[float]
    routing_decision: str

class FinalOutput(TypedDict):
    """ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ë  ê²°ê³¼ë¬¼"""
    response_text: str
    response_audio_url: Optional[str]

class GraphState(TypedDict):
    """ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€í†µí•˜ëŠ” ìƒíƒœ ê°ì²´"""
    input_data: WorkflowInput
    message_history: List[Dict[str, str]]
    intermediate: IntermediateState
    output: FinalOutput
    photo_info: Optional[Dict[str, Any]]  # ì‚¬ì§„ ì •ë³´ ì €ì¥
    session_id: Optional[str]  # ì„¸ì…˜ ID ì €ì¥
    _authenticated_client: Optional[Client]  # ì¸ì¦ëœ Supabase í´ë¼ì´ì–¸íŠ¸
    turn_count: int  # í˜„ì¬ í„´ ìˆ˜ (conversation_order ê¸°ë°˜)
    assessment_completed: Dict[str, bool]  # í‰ê°€ ì™„ë£Œ ìƒíƒœ {"time_orientation": bool, "language_naming": bool}

class DialogueWorkflow:
    """LangGraph ê¸°ë°˜ ëŒ€í™” ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ (settings ì‚¬ìš©)
        openai_key = settings.OPENAI_API_KEY
        supabase_url = settings.SUPABASE_URL
        supabase_key = settings.SUPABASE_ANON_KEY
        
        # LangSmith ì„¤ì •
        langsmith_tracing = settings.LANGSMITH_TRACING and settings.LANGSMITH_TRACING.lower() == "true"
        langsmith_project = settings.LANGSMITH_PROJECT or "memento-box-dialogue"
        
        # LangSmith í™˜ê²½ë³€ìˆ˜ ì„¤ì • (LangChainì´ ìë™ìœ¼ë¡œ ì½ë„ë¡)
        if settings.LANGSMITH_TRACING:
            os.environ["LANGSMITH_TRACING"] = settings.LANGSMITH_TRACING
        if settings.LANGSMITH_API_KEY:
            os.environ["LANGSMITH_API_KEY"] = settings.LANGSMITH_API_KEY
        if settings.LANGSMITH_PROJECT:
            os.environ["LANGSMITH_PROJECT"] = settings.LANGSMITH_PROJECT
        if settings.LANGSMITH_ENDPOINT:
            os.environ["LANGSMITH_ENDPOINT"] = settings.LANGSMITH_ENDPOINT
        
        if not openai_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        if not supabase_url:
            raise ValueError("SUPABASE_URL environment variable is required")
        if not supabase_key:
            raise ValueError("SUPABASE_ANON_KEY environment variable is required")
        
        try:
            # LangSmith ë©”íƒ€ë°ì´í„° ì„¤ì •
            langsmith_metadata = {
                "service": "dialogue_workflow",
                "version": "1.0",
                "environment": os.getenv("ENVIRONMENT", "development")
            }
            
            self.llm_mini = ChatOpenAI(
                model="gpt-4o-mini",
                api_key=openai_key,
                metadata=langsmith_metadata if langsmith_tracing else None
            )
            self.llm_nano = ChatOpenAI(
                model="gpt-4o-mini",
                max_tokens=256,
                api_key=openai_key,
                metadata=langsmith_metadata if langsmith_tracing else None
            )
            print(f"OpenAI LLM clients initialized successfully (LangSmith tracing: {langsmith_tracing})")
        except Exception as e:
            print(f"Failed to initialize OpenAI clients: {e}")
            raise
        
        try:
            # Supabase í´ë¼ì´ì–¸íŠ¸
            self.supabase: Client = create_client(
                supabase_url=supabase_url,
                supabase_key=supabase_key
            )
            print("Supabase client initialized successfully")
        except Exception as e:
            print(f"Failed to initialize Supabase client: {e}")
            raise
        
        try:
            # ì›Œí¬í”Œë¡œìš° êµ¬ì„±
            self.app = self._build_workflow()
            print("LangGraph workflow compiled successfully")
        except Exception as e:
            print(f"Failed to build LangGraph workflow: {e}")
            raise
    
    def _build_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(GraphState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("init_state", self.init_state_node)
        workflow.add_node("router", self.router_node)
        workflow.add_node("time_orientation", self.time_orientation_node)
        workflow.add_node("language_naming", self.language_naming_node)
        workflow.add_node("standard_response", self.standard_response_node)
        workflow.add_node("cache_retrieve", self.cache_retrieve_and_evaluate_node)
        workflow.add_node("fallback", self.fallback_node)
        
        # ì§„ì…ì  ì„¤ì •
        workflow.set_entry_point("init_state")
        
        # ì—£ì§€ ì •ì˜
        workflow.add_edge("init_state", "router")
        workflow.add_conditional_edges(
            "router",
            self._route_decision,
            {
                "time_orientation": "time_orientation",
                "language_naming": "language_naming", 
                "standard_chat": "standard_response",
                "assessment_chat": "cache_retrieve"
            }
        )
        workflow.add_edge("time_orientation", END)
        workflow.add_edge("language_naming", END)
        workflow.add_edge("standard_response", END)
        workflow.add_conditional_edges(
            "cache_retrieve",
            self._cache_decision,
            {
                "use_cache": END,
                "use_fallback": "fallback"
            }
        )
        workflow.add_edge("fallback", END)
        
        return workflow.compile()
    
    def init_state_node(self, state: GraphState) -> GraphState:
        """ìƒíƒœ ì´ˆê¸°í™” ë…¸ë“œ: DBì—ì„œ ëŒ€í™” ê¸°ë¡ ë° ì‚¬ì§„ ì •ë³´ ì¡°íšŒ"""
        conversation_id = state["input_data"]["conversation_id"]
        user_id = state["input_data"]["user_id"]
        photo_context = state["input_data"]["photo_context"]
        
        # ìƒíƒœì—ì„œ ì¸ì¦ëœ í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        client = state.get("_authenticated_client", self.supabase)
        
        print(f"ğŸ” ìƒíƒœ ì´ˆê¸°í™”: conversation_id={conversation_id}, user_id={user_id}")
        
        try:
            # ì‚¬ì§„ ì •ë³´ ì¡°íšŒ (photo_contextì— photo_idê°€ ìˆëŠ” ê²½ìš°)
            photo_info = None
            if photo_context.get("photo_id"):
                try:
                    photo_response = client.table("photos").select(
                        "id, filename, file_path, description, tags, location_name, photo_analyze_result"
                    ).eq("id", photo_context["photo_id"]).single().execute()
                    
                    if photo_response.data:
                        photo_info = photo_response.data
                        print(f"ğŸ“· ì‚¬ì§„ ì •ë³´ ë¡œë“œë¨: {photo_info}")
                except Exception as photo_error:
                    print(f"âŒ ì‚¬ì§„ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {photo_error}")
            
            # conversation_idë¥¼ session_idë¡œ ì‚¬ìš© (main.pyì—ì„œ ì´ë¯¸ ì„¸ì…˜ ìƒì„±ë¨)
            session_id = conversation_id
            print(f"âœ… ì„¸ì…˜ ID ì„¤ì •: {session_id}")
            
            # í•´ë‹¹ ì„¸ì…˜ì˜ ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ ì¡°íšŒ
            conversations_response = client.table("conversations").select(
                "id, ai_output, user_input, conversation_order"
            ).eq("session_id", session_id).order("conversation_order").execute()
            
            print(f"ğŸ’¬ ê¸°ì¡´ ëŒ€í™” ë‚´ì—­: {len(conversations_response.data) if conversations_response.data else 0}ê°œ")
            
            # í˜„ì¬ í„´ ìˆ˜ ê³„ì‚° (ë‹¤ìŒ conversation_order)
            current_turn = len(conversations_response.data) + 1 if conversations_response.data else 1
            print(f"ğŸ“Š í˜„ì¬ í„´ ìˆ˜: {current_turn}")
            
            # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ êµ¬ì„±
            system_content = "ë‹¹ì‹ ì€ ì¹˜ë§¤ ì§„ë‹¨ì„ ìœ„í•œ ë”°ëœ»í•œ ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
            if photo_info:
                system_content += f" í˜„ì¬ ì‚¬ì§„ ì •ë³´: íŒŒì¼ëª…({photo_info.get('filename', 'N/A')}), ì„¤ëª…({photo_info.get('description', 'N/A')}), ìœ„ì¹˜({photo_info.get('location_name', 'N/A')}), íƒœê·¸({', '.join(photo_info.get('tags', []))})"
            
            message_history = [{"role": "system", "content": system_content}]
            
            # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶”ê°€
            if conversations_response.data:
                for conv in conversations_response.data:
                    if conv.get("ai_output"):
                        message_history.append({
                            "role": "assistant", 
                            "content": conv["ai_output"]
                        })
                    if conv.get("user_input"):
                        message_history.append({
                            "role": "user", 
                            "content": conv["user_input"]
                        })
            
            state["message_history"] = message_history
            state["intermediate"] = {"cache_score": None, "routing_decision": ""}
            state["output"] = {"response_text": "", "response_audio_url": None}
            state["turn_count"] = current_turn
            state["assessment_completed"] = {"time_orientation": False, "language_naming": False}
            
            # photo_infoì™€ session_idë¥¼ ìƒíƒœì— ì €ì¥
            if photo_info:
                state["photo_info"] = photo_info
            state["session_id"] = session_id
            
        except Exception as e:
            print(f"Database operation failed: {e}")
            # ì—ëŸ¬ì‹œ ê¸°ë³¸ ìƒíƒœ ì„¤ì •
            system_content = "ë‹¹ì‹ ì€ ì¹˜ë§¤ ì§„ë‹¨ì„ ìœ„í•œ ë”°ëœ»í•œ ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
            state["message_history"] = [{"role": "system", "content": system_content}]
            state["intermediate"] = {"cache_score": None, "routing_decision": ""}
            state["output"] = {"response_text": "", "response_audio_url": None}
            state["session_id"] = conversation_id
            state["turn_count"] = 1  # ì—ëŸ¬ì‹œ ì²« ë²ˆì§¸ í„´ìœ¼ë¡œ ê°€ì •
            state["assessment_completed"] = {"time_orientation": False, "language_naming": False}
        
        return state
    
    def router_node(self, state: GraphState) -> GraphState:
        """ë¼ìš°í„° ë…¸ë“œ: í„´ ìˆ˜ì— ë”°ë¥¸ í‰ê°€ ë¼ìš°íŒ…"""
        turn_count = state.get("turn_count", 1)
        user_message = state["input_data"]["user_message"]
        
        print(f"ğŸ”€ ë¼ìš°í„° ë…¸ë“œ: turn_count={turn_count}")
        
        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í„´ì€ rule-basedë¡œ í‰ê°€ ë…¸ë“œë¡œ ë¼ìš°íŒ…
        if turn_count == 1:
            routing_decision = "time_orientation"
            print("ğŸ• ì²« ë²ˆì§¸ í„´ â†’ ì‹œê°„ ì§€ë‚¨ë ¥ í‰ê°€")
        elif turn_count == 2:
            routing_decision = "language_naming"
            print("ğŸ—£ï¸ ë‘ ë²ˆì§¸ í„´ â†’ ì–¸ì–´ê¸°ëŠ¥ í‰ê°€")
        else:
            # ì„¸ ë²ˆì§¸ í„´ë¶€í„°ëŠ” ê¸°ì¡´ LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©
            print("ğŸ’¬ ì„¸ ë²ˆì§¸ í„´ ì´í›„ â†’ ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ì‚¬ìš©")
            
            # ê¸°ì¡´ ë¼ìš°í„° ë¡œì§ ì‚¬ìš©
            message_history = state["message_history"]
            
            # dialogue_prompt.pyì˜ ROUTER_PROMPT ì‚¬ìš©
            from .dialogue_prompt import ROUTER_PROMPT
            routing_prompt = ROUTER_PROMPT
            
            try:
                response = self.llm_mini.invoke([
                    SystemMessage(content=routing_prompt),
                    HumanMessage(content=f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\nëŒ€í™” íˆìŠ¤í† ë¦¬: {message_history}")
                ])
                
                routing_decision = response.content.strip().lower()
                if routing_decision not in ["standard_chat", "assessment_chat"]:
                    routing_decision = "standard_chat"  # ê¸°ë³¸ê°’
                    
            except Exception as e:
                print(f"Router decision failed: {e}")
                routing_decision = "standard_chat"
        
        state["intermediate"]["routing_decision"] = routing_decision
        print(f"âœ… ë¼ìš°íŒ… ê²°ì •: {routing_decision}")
        
        return state
    
    def time_orientation_node(self, state: GraphState) -> GraphState:
        """ì‹œê°„ ì§€ë‚¨ë ¥ í‰ê°€ ë…¸ë“œ (ì²« ë²ˆì§¸ í„´)"""
        print("ğŸ• ì‹œê°„ ì§€ë‚¨ë ¥ í‰ê°€ ë…¸ë“œ ì‹¤í–‰")
        
        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        now = datetime.now()
        current_year = now.year
        current_month = now.month
        
        # TIME_ORIENTATION_PROMPT ì‚¬ìš©
        from .dialogue_prompt import TIME_ORIENTATION_PROMPT
        
        try:
            # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
            time_question = TIME_ORIENTATION_PROMPT.format(
                current_year=current_year,
                current_month=current_month
            )
            
            state["output"]["response_text"] = time_question.strip()
            state["assessment_completed"]["time_orientation"] = True
            print(f"âœ… ì‹œê°„ ì§€ë‚¨ë ¥ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: {current_year}ë…„ {current_month}ì›”")
            
        except Exception as e:
            print(f"âŒ ì‹œê°„ ì§€ë‚¨ë ¥ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            state["output"]["response_text"] = f"ê¸°ì–µ ì—¬í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì—¬í–‰ì„ ë– ë‚˜ëŠ” ì˜¤ëŠ˜ì€ {current_year}ë…„ {current_month}ì›” ë©°ì¹ ì¸ê°€ìš”?"
        
        return state
    
    def language_naming_node(self, state: GraphState) -> GraphState:
        """ì–¸ì–´ê¸°ëŠ¥(ì´ë¦„ëŒ€ê¸°) í‰ê°€ ë…¸ë“œ (ë‘ ë²ˆì§¸ í„´)"""
        print("ğŸ—£ï¸ ì–¸ì–´ê¸°ëŠ¥ í‰ê°€ ë…¸ë“œ ì‹¤í–‰")
        
        photo_info = state.get("photo_info", {})
        
        try:
            # ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ì—ì„œ key_objects ì¶”ì¶œ
            photo_analyze_result = photo_info.get('photo_analyze_result', {})
            key_objects = photo_analyze_result.get('key_objects', [])
            
            if not key_objects:
                # key_objectsê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
                state["output"]["response_text"] = "ë‹µë³€ ê°ì‚¬í•´ìš”. ê·¸ëŸ¼ ì§€ê¸ˆë¶€í„° ê³¼ê±°ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ ë³´ê² ìŠµë‹ˆë‹¤... 3.. 2.. 1. ì´ ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” ê²ƒë“¤ì„ í•˜ë‚˜ì”© ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
                print("âš ï¸ ì‚¬ì§„ì— key_objectsê°€ ì—†ì–´ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©")
            else:
                # ì²« ë²ˆì§¸ ê°ì²´ë¥¼ ì„ íƒí•˜ì—¬ ì§ˆë¬¸ ìƒì„±
                selected_object = key_objects[0] if key_objects else "ë¬¼ê±´"
                
                # ì‚¬ì§„ì´ ì°íŒ ì—°ë„ ê³„ì‚° (taken_at ê¸°ì¤€, ì—†ìœ¼ë©´ created_at ì‚¬ìš©)
                taken_at = photo_info.get('taken_at') or photo_info.get('created_at')
                years_diff = 0
                if taken_at:
                    try:
                        # ISO í˜•ì‹ì˜ ë‚ ì§œ íŒŒì‹±
                        if isinstance(taken_at, str):
                            taken_date = datetime.fromisoformat(taken_at.replace('Z', '+00:00'))
                        else:
                            taken_date = taken_at
                        
                        years_diff = datetime.now().year - taken_date.year
                        if years_diff < 0:
                            years_diff = 0
                    except Exception as date_error:
                        print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {date_error}")
                        years_diff = 0
                
                # NAMING_PROMPT ì‚¬ìš©
                from .dialogue_prompt import NAMING_PROMPT
                
                photo_description = photo_info.get('description', 'ì‚¬ì§„')
                
                # ê°ì²´ ìœ„ì¹˜ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
                if years_diff > 0:
                    response_text = f"ë‹µë³€ ê°ì‚¬í•´ìš”. ê·¸ëŸ¼ ì§€ê¸ˆë¶€í„° {years_diff}ë…„ ì „ìœ¼ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ ë³´ê² ìŠµë‹ˆë‹¤... 3.. 2.. 1. ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” {selected_object} ê°™ì€ ê²ƒì´ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
                else:
                    response_text = "ë‹µë³€ ê°ì‚¬í•´ìš”. ê·¸ëŸ¼ ì§€ê¸ˆë¶€í„° ê³¼ê±°ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ ë³´ê² ìŠµë‹ˆë‹¤... 3.. 2.. 1. ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” ê²ƒë“¤ ì¤‘ í•˜ë‚˜ë¥¼ ê°€ë¦¬ì¼œì„œ ì´ë¦„ì„ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
                
                state["output"]["response_text"] = response_text
                print(f"âœ… ì–¸ì–´ê¸°ëŠ¥ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: {selected_object} ê¸°ë°˜")
            
            state["assessment_completed"]["language_naming"] = True
            
        except Exception as e:
            print(f"âŒ ì–¸ì–´ê¸°ëŠ¥ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            state["output"]["response_text"] = "ë‹µë³€ ê°ì‚¬í•´ìš”. ê·¸ëŸ¼ ì§€ê¸ˆë¶€í„° ê³¼ê±°ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ ë³´ê² ìŠµë‹ˆë‹¤... 3.. 2.. 1. ì´ ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” ê²ƒ ì¤‘ í•˜ë‚˜ë¥¼ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
            state["assessment_completed"]["language_naming"] = True
        
        return state
    
    def standard_response_node(self, state: GraphState) -> GraphState:
        """ì¼ë°˜ ì‘ë‹µ ìƒì„± ë…¸ë“œ: ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™”"""
        user_message = state["input_data"]["user_message"]
        photo_context = state["input_data"]["photo_context"]
        photo_info = state.get("photo_info", {})
        message_history = state.get("message_history", [])
        
        # ì‚¬ì§„ ì •ë³´ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        photo_description = ""
        if photo_info:
            # ê¸°ë³¸ ì‚¬ì§„ ì •ë³´
            basic_info = f"ì‚¬ì§„ ì •ë³´: {photo_info.get('description', '')}, ìœ„ì¹˜: {photo_info.get('location_name', '')}, íƒœê·¸: {', '.join(photo_info.get('tags', []))}"
            
            # ë¶„ì„ ê²°ê³¼ ì¶”ê°€
            analyze_result = photo_info.get('photo_analyze_result')
            if analyze_result:
                analysis_info = []
                if analyze_result.get('caption'):
                    analysis_info.append(f"ë¶„ì„ ì„¤ëª…: {analyze_result['caption']}")
                if analyze_result.get('mood'):
                    analysis_info.append(f"ë¶„ìœ„ê¸°: {analyze_result['mood']}")
                if analyze_result.get('key_objects'):
                    analysis_info.append(f"ì£¼ìš” ê°ì²´: {', '.join(analyze_result['key_objects'])}")
                if analyze_result.get('people_description'):
                    analysis_info.append(f"ì¸ë¬¼: {analyze_result['people_description']}")
                if analyze_result.get('time_of_day'):
                    analysis_info.append(f"ì‹œê°„ëŒ€: {analyze_result['time_of_day']}")
                
                if analysis_info:
                    photo_description = f"{basic_info}\në¶„ì„ ê²°ê³¼: {', '.join(analysis_info)}"
                else:
                    photo_description = basic_info
            else:
                photo_description = basic_info
        
        # dialogue_prompt.pyì˜ STANDARD_RESPONSE_PROMPT ì‚¬ìš© (í…œí”Œë¦¿ ë³€ìˆ˜ ì ìš©)
        conversation_prompt = STANDARD_RESPONSE_PROMPT.format(
            photo_description=photo_description,
            user_message=user_message,
            message_history=message_history
        )
        
        try:
            response = self.llm_mini.invoke([
                SystemMessage(content=conversation_prompt),
                HumanMessage(content=user_message)
            ])
            
            state["output"]["response_text"] = response.content.strip()
            
        except Exception as e:
            print(f"Standard response generation failed: {e}")
            state["output"]["response_text"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        
        return state
    
    def cache_retrieve_and_evaluate_node(self, state: GraphState) -> GraphState:
        """ìºì‹œ ê²€ìƒ‰ ë° í‰ê°€ ë…¸ë“œ: ì¸ì§€ê¸°ëŠ¥ í‰ê°€ ì§ˆë¬¸ ê²€ìƒ‰"""
        user_message = state["input_data"]["user_message"]
        message_history = state.get("message_history", [])
        
        try:
            # Supabaseì—ì„œ CIST ì§ˆë¬¸ í…œí”Œë¦¿ ê²€ìƒ‰
            response = self.supabase.table("cist_question_templates").select(
                "*"
            ).limit(5).execute()
            
            if response.data:
                # dialogue_prompt.pyì˜ CACHE_RETRIEVE_AND_EVALUATE_PROMPT ì‚¬ìš©
                # ì‹¤ì œ êµ¬í˜„ì‹œì—ëŠ” ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì§ˆë¬¸ ì„ íƒ
                evaluate_prompt = CACHE_RETRIEVE_AND_EVALUATE_PROMPT
                
                # ê°„ë‹¨í•œ ìœ ì‚¬ë„ í‰ê°€ (ì‹¤ì œë¡œëŠ” ë²¡í„° DB ì‚¬ìš© ê¶Œì¥)
                best_question = response.data[0]
                cache_score = 0.9  # ì„ì‹œ ì ìˆ˜
                
                state["intermediate"]["cache_score"] = cache_score
                state["output"]["response_text"] = best_question["template_text"]
            else:
                state["intermediate"]["cache_score"] = 0.3  # ë‚®ì€ ì ìˆ˜
                
        except Exception as e:
            print(f"Cache retrieval failed: {e}")
            state["intermediate"]["cache_score"] = 0.3
        
        return state
    
    def fallback_node(self, state: GraphState) -> GraphState:
        """ëŒ€ì²´ ì‘ë‹µ ì²˜ë¦¬ ë…¸ë“œ: ê²½ëŸ‰ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        user_message = state["input_data"]["user_message"]
        conversation_id = state["input_data"]["conversation_id"]
        photo_context = state["input_data"]["photo_context"]
        photo_info = state.get("photo_info", {})
        message_history = state.get("message_history", [])
        
        # ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ ìš”ì•½ (fallbackìš© ê°„ë‹¨ ë²„ì „)
        photo_metadata = ""
        if photo_info:
            analyze_result = photo_info.get('photo_analyze_result')
            if analyze_result:
                context_parts = []
                if analyze_result.get('caption'):
                    context_parts.append(f"ì‚¬ì§„: {analyze_result['caption'][:50]}...")
                if analyze_result.get('mood'):
                    context_parts.append(f"ë¶„ìœ„ê¸°: {analyze_result['mood']}")
                
                if context_parts:
                    photo_metadata = f"ì°¸ê³ : {', '.join(context_parts)}"
        
        # dialogue_prompt.pyì˜ FALLBACK_PROMPT ì‚¬ìš©
        fallback_prompt = FALLBACK_PROMPT
        
        try:
            # í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨
            context_info = f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}\nì‚¬ì§„ ë©”íƒ€ë°ì´í„°: {photo_metadata}\nìµœê·¼ ëŒ€í™”: {message_history[-2:] if message_history else []}"
            
            response = self.llm_nano.invoke([
                SystemMessage(content=fallback_prompt),
                HumanMessage(content=context_info)
            ])
            
            state["output"]["response_text"] = response.content.strip()
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³ í’ˆì§ˆ ì§ˆë¬¸ ìƒì„± ìš”ì²­
            self._schedule_background_task(user_message, conversation_id, photo_context)
            
        except Exception as e:
            print(f"Fallback response failed: {e}")
            state["output"]["response_text"] = "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤."
        
        return state
    
    def _schedule_background_task(self, user_message: str, conversation_id: str, photo_context: dict):
        """Celeryë¥¼ í†µí•œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ë§"""
        try:
            from tasks import generate_high_quality_questions
            
            context = {
                "user_message": user_message,
                "conversation_id": conversation_id, 
                "photo_context": photo_context
            }
            
            # ë¹„ë™ê¸° ì‘ì—… ë°œí–‰
            generate_high_quality_questions.delay(context)
            print(f"Background task scheduled for conversation: {conversation_id}")
            
        except Exception as e:
            print(f"Failed to schedule background task: {e}")
    
    def _route_decision(self, state: GraphState) -> str:
        """ë¼ìš°í„° ê²°ì •ì— ë”°ë¥¸ ê²½ë¡œ ì„ íƒ"""
        return state["intermediate"]["routing_decision"]
    
    def _cache_decision(self, state: GraphState) -> str:
        """ìºì‹œ ì ìˆ˜ì— ë”°ë¥¸ ê²½ë¡œ ì„ íƒ"""
        cache_score = state["intermediate"]["cache_score"]
        if cache_score and cache_score >= 0.85:
            return "use_cache"
        return "use_fallback"
    
    async def _save_conversation_to_db(self, state: GraphState, authenticated_client: Client = None) -> None:
        """ëŒ€í™” ë‚´ìš©ì„ DBì— ì €ì¥"""
        try:
            # ì¸ì¦ëœ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
            client = authenticated_client if authenticated_client else self.supabase
            
            session_id = state.get("session_id")
            user_message = state["input_data"]["user_message"]
            ai_response = state["output"]["response_text"]
            photo_context = state["input_data"]["photo_context"]
            user_id = state["input_data"]["user_id"]
            
            print(f"ğŸ’¾ ëŒ€í™” ì €ì¥ ì‹œë„: session_id={session_id}, user_id={user_id}")
            
            if not session_id:
                print("âŒ session_id ì—†ìŒ, ëŒ€í™” ì €ì¥ ê±´ë„ˆëœ€")
                return
            
            # ë‹¤ìŒ conversation_order ê³„ì‚°
            count_response = client.table("conversations").select(
                "conversation_order"
            ).eq("session_id", session_id).execute()
            
            next_order = len(count_response.data) + 1 if count_response.data else 1
            print(f"ğŸ“Š ëŒ€í™” ìˆœì„œ: {next_order}")
            
            # í‰ê°€ ìœ í˜• ê²°ì •
            routing_decision = state["intermediate"].get("routing_decision", "")
            question_type = "open_ended"  # ê¸°ë³¸ê°’
            cist_category = None
            is_cist_item = False
            
            if routing_decision == "time_orientation":
                question_type = "cist_orientation"
                cist_category = "orientation_time"
                is_cist_item = True
                print("ğŸ“Š ì‹œê°„ ì§€ë‚¨ë ¥ í‰ê°€ë¡œ ë¶„ë¥˜")
            elif routing_decision == "language_naming":
                question_type = "cist_language"
                cist_category = "language_naming"
                is_cist_item = True
                print("ğŸ“Š ì–¸ì–´ê¸°ëŠ¥ í‰ê°€ë¡œ ë¶„ë¥˜")
            
            # ëŒ€í™” ë ˆì½”ë“œ ìƒì„±
            conversation_data = {
                "session_id": session_id,
                "user_id": user_id,
                "photo_id": photo_context.get("photo_id"),
                "conversation_order": next_order,
                "ai_output": ai_response,
                "question_type": question_type,
                "cist_category": cist_category,
                "user_input": user_message,
                "is_cist_item": is_cist_item
            }
            
            print(f"ğŸ“ ëŒ€í™” ë°ì´í„°: {conversation_data}")
            
            insert_response = client.table("conversations").insert(conversation_data).execute()
            if insert_response.data:
                print(f"âœ… ëŒ€í™” ì €ì¥ ì„±ê³µ: {insert_response.data[0]['id']}")
            else:
                print("âŒ ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"âŒ ëŒ€í™” ì €ì¥ DB ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥
            import traceback
            print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

    async def process_message(self, input_data: WorkflowInput, authenticated_client: Client = None) -> FinalOutput:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ì§„ì…ì """
        initial_state = {
            "input_data": input_data,
            "message_history": [],
            "intermediate": {"cache_score": None, "routing_decision": ""},
            "output": {"response_text": "", "response_audio_url": None},
            "photo_info": None,
            "session_id": None,
            "turn_count": 1,  # ê¸°ë³¸ê°’, init_state_nodeì—ì„œ ì‹¤ì œ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            "assessment_completed": {"time_orientation": False, "language_naming": False},
            "_authenticated_client": authenticated_client
        }
        
        try:
            print(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹œì‘: conversation_id={input_data['conversation_id']}")
            
            final_state = await self.app.ainvoke(initial_state)
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: conversation_id={input_data['conversation_id']}")
            
            # ëŒ€í™” ë‚´ìš©ì„ DBì— ì €ì¥
            if final_state["output"]["response_text"]:
                try:
                    await self._save_conversation_to_db(final_state, authenticated_client)
                    print("âœ… ëŒ€í™” DB ì €ì¥ ì™„ë£Œ")
                except Exception as db_error:
                    print(f"âŒ ëŒ€í™” DB ì €ì¥ ì‹¤íŒ¨: {db_error}")
                    # ëŒ€í™” ì €ì¥ ì‹¤íŒ¨í•´ë„ ì‘ë‹µì€ ì „ì†¡
            
            return final_state["output"]
        except Exception as e:
            import traceback
            print(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: conversation_id={input_data['conversation_id']}, error={e}")
            print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return {
                "response_text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "response_audio_url": None
            }
